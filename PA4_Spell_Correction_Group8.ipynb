{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3i3m9JjeM5U5"
   },
   "source": [
    "# **Programming Assessment \\#4**\n",
    "\n",
    "Names: Alyanna Abalos, Loben Tipan\n",
    "\n",
    "More information on the assessment is found in our Canvas course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxtmCAZwNoeU"
   },
   "source": [
    "# **Load Data**\n",
    "\n",
    "*While you don't have to separate your code into blocks, it might be easier if you separated loading your data from actually implementation of your code. Consider placing all loading of data into the code block below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CbvxU2oTM4IV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('count_1edit.txt', 'r', encoding='ISO-8859-1') as file:\n",
    "    data_count_1edit = file.read()\n",
    "\n",
    "with open('spell_errors.txt', 'r', encoding='ISO-8859-1') as file:\n",
    "    data_spell_errors = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8YCZLi-N0uR"
   },
   "source": [
    "# **Error Model Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('e', 'i'), 0.3411458333333333), (('a', 'e'), 0.24160316116285635), (('i', 'e'), 0.21761219305673157), (('e', 'a'), 0.2843583902809415), (('a', 'i'), 0.20796130952380953)] \n",
      "\n",
      "\n",
      "[('raining', ['rainning', 'raning']), ('writings', ['writtings']), ('disparagingly', ['disparingly']), ('yellow', ['yello']), ('four', ['forer', 'fours', 'fuore', 'fore*5', 'for*4'])]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "error_model = {}\n",
    "for line in data_count_1edit.splitlines():\n",
    "    parts = line.split('|')\n",
    "    w = parts[0].strip() \n",
    "    \n",
    "    if len(parts) < 2:\n",
    "        continue\n",
    "\n",
    "    c_split = parts[1].split()\n",
    "    if len(c_split) < 2:\n",
    "        continue\n",
    "\n",
    "    c = c_split[0]\n",
    "    count = int(c_split[1])\n",
    "    \n",
    "    error_model[(w, c)] = count\n",
    "\n",
    "total_counts_for_correct = defaultdict(int)\n",
    "for (corrupted, correct), count in error_model.items():\n",
    "    total_counts_for_correct[correct] += count\n",
    "\n",
    "for (corrupted, correct) in list(error_model.keys()):\n",
    "    error_model[(corrupted, correct)] /= total_counts_for_correct[correct]\n",
    "\n",
    "spell_errors = {}\n",
    "for line in data_spell_errors.splitlines():\n",
    "    correct_word, misspelled_words_part = line.split(\":\")\n",
    "    misspelled_words = [word.strip() for word in misspelled_words_part.split(',')]\n",
    "    spell_errors[correct_word.strip()] = misspelled_words\n",
    "\n",
    "print(list(error_model.items())[:5], \"\\n\\n\")\n",
    "print(list(spell_errors.items())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Language Model Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/alyannaabalos/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "\n",
    "from nltk.corpus import gutenberg\n",
    "from collections import Counter\n",
    "\n",
    "def build_language_model():\n",
    "    words = gutenberg.words()\n",
    "    words = [word.lower() for word in words if word.isalpha()]\n",
    "    word_freq = Counter(words)\n",
    "    total_words = sum(word_freq.values())\n",
    "    language_model = {word: freq / total_words for word, freq in word_freq.items()}\n",
    "    return language_model\n",
    "\n",
    "language_model = build_language_model()\n",
    "vocabulary = set(language_model.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Candidate Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates(word, vocabulary):\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    candidates = []\n",
    "    \n",
    "    for i in range(len(word)):\n",
    "        candidate = word[:i] + word[i+1:]\n",
    "        if candidate in vocabulary:\n",
    "            candidates.append((candidate, \"del\"))\n",
    "    \n",
    "    for i in range(len(word) + 1):\n",
    "        for letter in alphabet:\n",
    "            candidate = word[:i] + letter + word[i:]\n",
    "            if candidate in vocabulary:\n",
    "                candidates.append((candidate, \"ins\"))\n",
    "    \n",
    "    for i in range(len(word)):\n",
    "        for letter in alphabet:\n",
    "            if word[i] != letter:\n",
    "                candidate = word[:i] + letter + word[i+1:]\n",
    "                if candidate in vocabulary:\n",
    "                    candidates.append((candidate, \"sub\"))\n",
    "    \n",
    "    for i in range(len(word) - 1):\n",
    "        candidate = word[:i] + word[i+1] + word[i] + word[i+2:]\n",
    "        if candidate in vocabulary:\n",
    "            candidates.append((candidate, \"tra\"))\n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Edit Identifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_character_edit(word, candidate, operation):\n",
    "    \"\"\"Return the character edit operation between word and candidate as a tuple.\"\"\"\n",
    "    if operation == \"sub\":\n",
    "        for i in range(len(word)):\n",
    "            if word[i] != candidate[i]:\n",
    "                return (word[i], candidate[i]) \n",
    "    elif operation == \"ins\":\n",
    "        for i in range(len(word)):\n",
    "            if i == len(candidate) or word[i] != candidate[i]:\n",
    "                return (\"\", candidate[i]) \n",
    "        return (\"\", candidate[-1])\n",
    "    elif operation == \"del\":\n",
    "        for i in range(len(candidate)):\n",
    "            if i == len(word) or word[i] != candidate[i]:\n",
    "                return (word[i], \"\") \n",
    "        return (word[-1], \"\")\n",
    "    elif operation == \"tra\":\n",
    "        for i in range(len(word) - 1):\n",
    "            if (word[i] != candidate[i]) and (word[i] == candidate[i+1]) and (word[i+1] == candidate[i]):\n",
    "                return (word[i]+word[i+1], candidate[i]+candidate[i+1])\n",
    "    return None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Probabilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correction_probabilities(word, candidates, error_model, language_model):\n",
    "    probabilities = []\n",
    "    \n",
    "    for candidate, op in candidates:\n",
    "        char_edit = get_character_edit(word, candidate, op)\n",
    "        p_w_given_c = error_model.get(char_edit, 0)  \n",
    "        p_c = language_model.get(candidate, 0)    \n",
    "        p_candidate_score = p_c * p_w_given_c\n",
    "        probabilities.append((candidate, op, p_c, p_w_given_c, p_candidate_score))\n",
    "\n",
    "    probabilities.sort(key=lambda x: x[-1], reverse=True)\n",
    "    \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a word to check:  frerdom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            Candidate       Edit Type  Edit                 P(c)       P(w|c)     P(c) x P(w|c)\n",
      "frerdom         freedom         sub        r|e                  0.000029   0.007621   2.176924e-07\n"
     ]
    }
   ],
   "source": [
    "word = input(\"Enter a word to check: \").lower()\n",
    "candidates = generate_candidates(word, vocabulary)\n",
    "probabilities = compute_correction_probabilities(word, candidates, error_model, language_model)\n",
    "\n",
    "if word in vocabulary:\n",
    "    print(f\"'{word}' is already correctly spelled.\")\n",
    "else:\n",
    "    header = \"{:<15} {:<15} {:<10} {:<20} {:<10} {:<10} {:<10}\"\n",
    "    print(header.format(\"Word\", \"Candidate\", \"Edit Type\", \"Edit\", \"P(c)\", \"P(w|c)\", \"P(c) x P(w|c)\"))\n",
    "    for row in probabilities:\n",
    "        candidate, op, p_c, p_w_given_c, p_candidate_score = row\n",
    "        char_edit_str = get_character_edit(word, candidate, op)\n",
    "        # Now using the correct variables in the print statement\n",
    "        print(header.format(word, candidate, op, \"{}|{}\".format(*char_edit_str) if char_edit_str else \"N/A\", f\"{p_c:.6f}\", f\"{p_w_given_c:.6f}\", f\"{p_candidate_score:.6e}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3i3m9JjeM5U5"
   },
   "source": [
    "# **Programming Assessment \\#5**\n",
    "\n",
    "Names: Alyanna Abalos, Loben Tipan\n",
    "\n",
    "More information on the assessment is found in our Canvas course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxtmCAZwNoeU"
   },
   "source": [
    "# **Load Pre-trained Embeddings**\n",
    "\n",
    "*While you don't have to separate your code into blocks, it might be easier if you separated loading / downloading your data from the main part of your solution. Consider placing all loading of data into the code block below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CbvxU2oTM4IV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/alyannaabalos/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "import nltk\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import words\n",
    "\n",
    "word_vectors = api.load(\"word2vec-google-news-300\")\n",
    "nltk.download('words')\n",
    "english_words = set(words.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8YCZLi-N0uR"
   },
   "source": [
    "# **Your Implementation**\n",
    "\n",
    "*Again, you don't have to have everything in one block. Use the notebook according to your preferences with the goal of fulfilling the assessment in mind.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Word Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "VqKjpUrkOSnC"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_random_word(word_vectors, english_words):\n",
    "    valid_words = set(word_vectors.key_to_index.keys()) & english_words\n",
    "    valid_words = [word for word in valid_words if word in word_vectors.key_to_index]\n",
    "    if not valid_words:\n",
    "        raise ValueError(\"No valid words found that are common between the word vectors model and the nltk corpus.\")\n",
    "    random_word = random.choice(valid_words)\n",
    "    return random_word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_words(word_vectors, target_word, english_words, indices=[10, 50, 100]):\n",
    "    topn_value = max(indices) * 10\n",
    "    similar_words = word_vectors.most_similar(target_word, topn=topn_value)\n",
    "    \n",
    "    normal_similar_words = [(word, score) for word, score in similar_words if word in english_words]\n",
    "    \n",
    "    num_similar_words = len(normal_similar_words)\n",
    "\n",
    "    for idx in indices:\n",
    "        if idx <= num_similar_words:\n",
    "            word, score = normal_similar_words[idx - 1]\n",
    "            print(f\"{idx}th most similar word to '{target_word}': {word} with a similarity score of {score}\")\n",
    "        else:\n",
    "            print(f\"Only {num_similar_words} similar words were found for '{target_word}', not enough to show the {idx}th word.\")\n",
    "\n",
    "    return normal_similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_score(word_vectors, correct_word, guess, precision=8):\n",
    "    try:\n",
    "        similarity_score = word_vectors.similarity(correct_word, guess)\n",
    "        similarity_score = round(similarity_score, precision)\n",
    "        return similarity_score\n",
    "    except KeyError as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected word: foremost\n",
      "10th most similar word to 'foremost': biggest with a similarity score of 0.3866763710975647\n",
      "50th most similar word to 'foremost': distinguished with a similarity score of 0.3141373097896576\n",
      "100th most similar word to 'foremost': primacy with a similarity score of 0.28819724917411804\n",
      "\n",
      "Input your guess. Type 'q' to exit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your guess:  first\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.14847147464752197\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your guess:  front\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.028867339715361595\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your guess:  important\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.3441140651702881\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your guess:  foremost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 1.0\n",
      "Congratulations, you found the target word!\n"
     ]
    }
   ],
   "source": [
    "def semantle_dupe(word_vectors, english_words):\n",
    "    similarity = 0\n",
    "    try:\n",
    "        random_word = get_random_word(word_vectors, english_words)\n",
    "    except IndexError:\n",
    "        print(\"No valid words found in the model's vocabulary.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Randomly selected word: {random_word}\")\n",
    "    \n",
    "    try:\n",
    "        get_similar_words(word_vectors, random_word, english_words, indices=[10, 50, 100])\n",
    "    except KeyError as e:\n",
    "        return\n",
    "\n",
    "    print(\"\\nInput your guess. Type 'q' to exit.\\n\")\n",
    "    while True:\n",
    "        user_guess = input(\"Enter your guess: \").lower()\n",
    "        if user_guess == 'q':\n",
    "            print(f\"The target word was: {random_word}\")\n",
    "            break\n",
    "        similarity = get_similarity_score(word_vectors, random_word, user_guess)\n",
    "        if similarity is not None:\n",
    "            print(f\"Similarity score: {similarity}\")\n",
    "            if abs(similarity - 1.0) < 1e-7:\n",
    "                print(\"Congratulations, you found the target word!\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"Word not found in the model's vocabulary.\")\n",
    "\n",
    "\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    semantle_dupe(word_vectors, english_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
